{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ №2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продолжим обработку данных с Твиттера. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T06:34:06.318679Z",
     "start_time": "2020-09-02T06:34:06.313543Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import os\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T06:49:57.112938Z",
     "start_time": "2020-09-02T06:49:55.214121Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../lesson01/result.pkl.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T06:55:52.580458Z",
     "start_time": "2020-09-02T06:55:52.556969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0  #model   i love u take with u all the time in ...   \n",
       "4   5    0.0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  when father is dysfunctional and is so selfish...   \n",
       "1  thanks for lyft credit cannot use cause they d...   \n",
       "2                                bihday your majesty   \n",
       "3    model love you take with you all the time in ur   \n",
       "4                  factsguide society now motivation   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [when, father, is, dysfunctional, and, is, so,...   \n",
       "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, love, you, take, with, you, all, the, ...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                  [bihday, majesty]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
       "1  [thank, lyft, credit, use, caus, offer, wheelc...   \n",
       "2                                  [bihday, majesti]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                        [factsguid, societi, motiv]   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  [father, dysfunct, selfish, drag, kid, dysfunc...  \n",
       "1  [thank, lyft, credit, use, caus, offer, wheelc...  \n",
       "2                                  [bihday, majesti]  \n",
       "3                      [model, love, take, time, ur]  \n",
       "4                        [factsguid, societi, motiv]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T06:56:58.196222Z",
     "start_time": "2020-09-02T06:56:58.064272Z"
    }
   },
   "outputs": [],
   "source": [
    "tweet_stemmed = df['tweet_stemmed'].apply(lambda x: ' '.join(x))\n",
    "tweet_lemmatized = df['tweet_lemmatized'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создайте мешок слов с помощью sklearn.feature_extraction.text.CountVectorizer.fit_transform(). \n",
    "\n",
    "Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    "\n",
    "* Игнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    "* Ограничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    "* Исключим стоп-слова с помощью stop_words='english'.\n",
    "* Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью CountVectorizer.get_feature_names()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T06:59:06.957551Z",
     "start_time": "2020-09-02T06:59:06.953080Z"
    }
   },
   "outputs": [],
   "source": [
    "def bagCountVectorizer(documents):\n",
    "    vkt = sklearn.feature_extraction.text.CountVectorizer(stop_words='english', max_df=0.9, max_features=1000)\n",
    "    bag_of_words = vkt.fit_transform(documents)\n",
    "    feature_names = vkt.get_feature_names()\n",
    "    return pd.DataFrame(bag_of_words.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T06:59:22.200578Z",
     "start_time": "2020-09-02T06:59:21.191049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activ</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abl  absolut  accept  account  act  action  activ  actor  actual  ad  ...  \\\n",
       "0    0        0       0        0    0       0      0      0       0   0  ...   \n",
       "1    0        0       0        0    0       0      0      0       0   0  ...   \n",
       "2    0        0       0        0    0       0      0      0       0   0  ...   \n",
       "3    0        0       0        0    0       0      0      0       0   0  ...   \n",
       "4    0        0       0        0    0       0      0      0       0   0  ...   \n",
       "\n",
       "   yeah  year  yesterday  yo  yoga  york  young  youtub  yr  yummi  \n",
       "0     0     0          0   0     0     0      0       0   0      0  \n",
       "1     0     0          0   0     0     0      0       0   0      0  \n",
       "2     0     0          0   0     0     0      0       0   0      0  \n",
       "3     0     0          0   0     0     0      0       0   0      0  \n",
       "4     0     0          0   0     0     0      0       0   0      0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagCountVectorizer(tweet_stemmed).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T06:59:35.642138Z",
     "start_time": "2020-09-02T06:59:34.556753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activ</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abl  absolut  accept  account  act  action  activ  actor  actual  ad  ...  \\\n",
       "0    0        0       0        0    0       0      0      0       0   0  ...   \n",
       "1    0        0       0        0    0       0      0      0       0   0  ...   \n",
       "2    0        0       0        0    0       0      0      0       0   0  ...   \n",
       "3    0        0       0        0    0       0      0      0       0   0  ...   \n",
       "4    0        0       0        0    0       0      0      0       0   0  ...   \n",
       "\n",
       "   yeah  year  yesterday  yo  yoga  york  young  youtub  yr  yummi  \n",
       "0     0     0          0   0     0     0      0       0   0      0  \n",
       "1     0     0          0   0     0     0      0       0   0      0  \n",
       "2     0     0          0   0     0     0      0       0   0      0  \n",
       "3     0     0          0   0     0     0      0       0   0      0  \n",
       "4     0     0          0   0     0     0      0       0   0      0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagCountVectorizer(tweet_lemmatized).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создайте мешок слов с помощью sklearn.feature_extraction.text.TfidfVectorizer.fit_transform(). \n",
    "\n",
    "Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    "\n",
    "* Игнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    "* Ограничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    "* Исключим стоп-слова с помощью stop_words='english'.\n",
    "* Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью TfidfVectorizer.get_feature_names()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T07:01:30.189750Z",
     "start_time": "2020-09-02T07:01:30.184711Z"
    }
   },
   "outputs": [],
   "source": [
    "def bagTFiDFVectorizer(documents):\n",
    "    vkt = sklearn.feature_extraction.text.TfidfVectorizer(stop_words='english', max_df=0.9, max_features=1000)\n",
    "    bag_of_words = vkt.fit_transform(documents)\n",
    "    feature_names = vkt.get_feature_names()\n",
    "    return pd.DataFrame(bag_of_words.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T07:02:27.818796Z",
     "start_time": "2020-09-02T07:02:26.752534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activ</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abl  absolut  accept  account  act  action  activ  actor  actual   ad  ...  \\\n",
       "0  0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0  ...   \n",
       "1  0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0  ...   \n",
       "2  0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0  ...   \n",
       "3  0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0  ...   \n",
       "4  0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0  ...   \n",
       "\n",
       "   yeah  year  yesterday   yo  yoga  york  young  youtub   yr  yummi  \n",
       "0   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "1   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "2   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "3   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "4   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagTFiDFVectorizer(tweet_stemmed).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T07:02:34.766685Z",
     "start_time": "2020-09-02T07:02:33.735248Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activ</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abl  absolut  accept  account  act  action  activ  actor  actual  ad  ...  \\\n",
       "0    0        0       0        0    0       0      0      0       0   0  ...   \n",
       "1    0        0       0        0    0       0      0      0       0   0  ...   \n",
       "2    0        0       0        0    0       0      0      0       0   0  ...   \n",
       "3    0        0       0        0    0       0      0      0       0   0  ...   \n",
       "4    0        0       0        0    0       0      0      0       0   0  ...   \n",
       "\n",
       "   yeah  year  yesterday  yo  yoga  york  young  youtub  yr  yummi  \n",
       "0     0     0          0   0     0     0      0       0   0      0  \n",
       "1     0     0          0   0     0     0      0       0   0      0  \n",
       "2     0     0          0   0     0     0      0       0   0      0  \n",
       "3     0     0          0   0     0     0      0       0   0      0  \n",
       "4     0     0          0   0     0     0      0       0   0      0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagCountVectorizer(tweet_lemmatized).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Натренируем gensim.models.Word2Vec модель на наших данных.\n",
    "\n",
    "* Тренировать будем на токенизированных твитах combine_df['tweet_token']\n",
    "* Установим следующие параметры: size=200, window=5, min_count=2, sg = 1, hs = 0, negative = 10, workers= 32, seed = 34.\n",
    "* Используем функцию train() с параметром total_examples равным длине combine_df['tweet_token'], количество epochs установим 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T07:26:30.322762Z",
     "start_time": "2020-09-02T07:26:03.874463Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(df['tweet_token'], size=200, window=5, min_count=2, sg=1, hs=0, negative=10, workers=32, seed=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T07:27:53.538381Z",
     "start_time": "2020-09-02T07:26:30.327101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9142580, 11726520)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(df['tweet_token'], total_examples=df.shape[0], epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте немного потестируем нашу модель Word2Vec и посмотрим, как она работает. \n",
    "Мы зададим слово positive = \"dinner\", и модель вытащит из корпуса наиболее похожие слова c помощью функции most_similar. То же самое попробуем со словом \"trump\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T07:28:28.026363Z",
     "start_time": "2020-09-02T07:28:27.970903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bihdaydinner', 0.5622773766517639),\n",
       " ('tacotuesday', 0.5444235801696777),\n",
       " ('spaghetti', 0.5441312789916992),\n",
       " ('bolognese', 0.5384405851364136),\n",
       " ('cookout', 0.5259362459182739),\n",
       " ('shawarma', 0.5205472707748413),\n",
       " ('foodblogger', 0.5189213752746582),\n",
       " ('whoopppp', 0.5180895328521729),\n",
       " ('lastnight', 0.5164986848831177),\n",
       " ('sissy', 0.5144867897033691)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['dinner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T07:32:02.697823Z",
     "start_time": "2020-09-02T07:32:02.689674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('donald', 0.5608586668968201),\n",
       " ('suppoer', 0.5371034145355225),\n",
       " ('dumptrump', 0.534472644329071),\n",
       " ('donaldtrump', 0.5310478210449219),\n",
       " ('unfit', 0.5271764993667603),\n",
       " ('crony', 0.5171792507171631),\n",
       " ('impeachment', 0.5092316269874573),\n",
       " ('fuhered', 0.5089944005012512),\n",
       " ('chopra', 0.5048550367355347),\n",
       " ('phony', 0.5027928352355957)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['trump'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из приведенных выше примеров мы видим, что наша модель word2vec хорошо справляется с поиском наиболее похожих слов для данного слова. Но как она это делает? Она изучила векторы для каждого уникального слова наших данных и использует косинусное сходство, чтобы найти наиболее похожие векторы (слова).\n",
    "Давайте проверим векторное представление любого слова из нашего корпуса, например \"food\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T07:32:02.697823Z",
     "start_time": "2020-09-02T07:32:02.689674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.153489  ,  0.06428561,  0.3722034 ,  0.06064127, -0.69315016,\n",
       "        0.09973792, -0.01812078,  0.31044507,  0.26695278,  0.02499013,\n",
       "        0.29230306,  0.20830229, -0.7019274 ,  0.1590251 ,  0.25446993,\n",
       "       -0.00829136, -0.30274695,  0.3602547 , -0.34514144,  0.2308154 ,\n",
       "       -0.16903019, -0.45647216, -0.80663496,  0.1529653 ,  0.34445292,\n",
       "        0.38103506,  0.43576917,  0.29655367,  0.45724562, -0.47178194,\n",
       "        0.16313516, -0.06369594,  0.44221067,  0.02226402, -0.26856628,\n",
       "       -0.34542346, -0.2278957 ,  0.1894716 ,  0.3547875 ,  0.13324021,\n",
       "       -0.80412257, -0.20877096,  0.6555684 ,  0.7543548 , -0.15332378,\n",
       "        0.09594485,  0.38581765, -0.09959139, -0.33543912, -0.01400881,\n",
       "        0.4181444 ,  0.349115  , -0.20921816, -0.04592204,  0.11665294,\n",
       "        0.06410595,  0.45817414,  0.6064263 ,  0.54473484, -0.23088364,\n",
       "       -0.5586976 ,  0.10403078, -0.20473142, -0.03284184,  0.57176596,\n",
       "        0.87209374, -0.29178673,  0.24443777, -0.27210826,  0.6373826 ,\n",
       "        0.14235216,  0.81801885, -0.23793222,  0.21601762,  0.2747174 ,\n",
       "        0.21578705, -0.5655795 , -1.0569811 ,  0.3570619 , -0.6201609 ,\n",
       "       -0.0298189 ,  0.37323475, -0.4174432 ,  0.00325148,  0.15755272,\n",
       "        0.5462073 , -0.5052232 ,  0.31203255, -0.05375274, -0.3866936 ,\n",
       "       -0.49133846, -0.54215914, -0.67657   , -0.01446305, -0.42138904,\n",
       "       -0.9275409 , -0.30237696,  0.47410086, -0.13833892,  0.05608513,\n",
       "        0.6463313 ,  0.7253423 ,  0.5406112 , -0.32045993,  0.489461  ,\n",
       "        0.15659863, -0.77364594, -0.23027606,  0.36074   , -0.25414962,\n",
       "        0.32980096,  0.73169684, -0.34717527, -0.31803823,  0.9539034 ,\n",
       "       -0.18975525,  0.00473847, -1.0381975 , -0.3711367 , -0.39987123,\n",
       "        0.5570919 , -0.13655223, -0.61718667, -0.31242165,  0.4069949 ,\n",
       "       -0.47691533, -0.32533118,  0.15014961,  0.19859965,  0.2278087 ,\n",
       "       -0.17637914,  0.01261086,  0.2616793 ,  0.14778785,  0.48799857,\n",
       "        0.35551748, -0.4440099 , -0.14160112, -0.5867906 ,  1.0269115 ,\n",
       "       -0.3002821 ,  0.03126681, -0.46858916, -0.00916485, -0.73759407,\n",
       "       -0.4856427 ,  0.52309895, -0.91718864,  0.51041603,  0.57170296,\n",
       "       -0.21917076,  0.82985604, -0.06824505,  0.11908425,  0.5189406 ,\n",
       "       -0.47723886,  0.1344016 , -0.61917585, -0.1238239 ,  0.21111849,\n",
       "       -0.28040308, -0.4807732 , -0.421934  ,  0.7956204 ,  0.04245191,\n",
       "       -0.07363301,  0.60063547,  0.20368858, -0.08844454,  0.21455131,\n",
       "       -0.08013403, -0.19575769,  0.5226329 , -0.14945926,  0.39443877,\n",
       "        0.0391346 , -0.20894678, -0.14718439,  0.05461335, -0.01293472,\n",
       "        0.47104517, -0.5902133 , -0.5987065 ,  0.7684516 , -0.15459368,\n",
       "       -0.40386495,  0.00497545,  0.19631469,  0.11793983,  0.43506095,\n",
       "        0.5467312 , -0.32229492, -0.4812068 , -0.50294477, -0.46824855,\n",
       "        0.00863697,  0.1921929 , -0.6342944 , -0.03842387,  0.24815542],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"food\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Необходимо создать вектор для каждого твита\n",
    "Поскольку наши данные содержат твиты, а не только слова, нам придется придумать способ использовать векторы слов из модели word2vec для создания векторного представления всего твита. Существует простое решение этой проблемы, мы можем просто взять среднее значение всех векторов слов, присутствующих в твите. Длина результирующего вектора будет одинаковой, то есть 200. Мы повторим тот же процесс для всех твитов в наших данных и получим их векторы. Теперь у нас есть 200 функций word2vec для наших данных.\n",
    "\n",
    "Необходимо создать вектор для каждого твита, взяв среднее значение векторов слов, присутствующих в твите. В цикле сделать:  vec += model_w2v[word].reshape((1, size))\n",
    "и поделить финальный вектор на количество слов в твите.\n",
    "На выходе должен получиться wordvec_df.shape = (49159, 200).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T08:00:43.629742Z",
     "start_time": "2020-09-02T08:00:28.263654Z"
    }
   },
   "outputs": [],
   "source": [
    "def vecavg(tweets):\n",
    "    vec = np.zeros((200,))\n",
    "    cnt = 0\n",
    "    for i in tweets:\n",
    "        if i in model:\n",
    "            vec += model[i]\n",
    "            cnt += 1\n",
    "    return list(vec / cnt)\n",
    "    \n",
    "vectors = pd.DataFrame(list(df['tweet_token'].apply(vecavg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T08:00:52.784292Z",
     "start_time": "2020-09-02T08:00:52.741143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.019885</td>\n",
       "      <td>0.252414</td>\n",
       "      <td>-0.152997</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>-0.149843</td>\n",
       "      <td>-0.031965</td>\n",
       "      <td>-0.179896</td>\n",
       "      <td>0.281747</td>\n",
       "      <td>-0.110417</td>\n",
       "      <td>-0.083372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>-0.236222</td>\n",
       "      <td>0.138744</td>\n",
       "      <td>0.211952</td>\n",
       "      <td>-0.148704</td>\n",
       "      <td>-0.124724</td>\n",
       "      <td>-0.137383</td>\n",
       "      <td>-0.320532</td>\n",
       "      <td>0.016711</td>\n",
       "      <td>0.225106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.243932</td>\n",
       "      <td>-0.007327</td>\n",
       "      <td>-0.160880</td>\n",
       "      <td>0.026103</td>\n",
       "      <td>-0.215708</td>\n",
       "      <td>0.092421</td>\n",
       "      <td>-0.032565</td>\n",
       "      <td>0.176955</td>\n",
       "      <td>0.058125</td>\n",
       "      <td>0.112401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073019</td>\n",
       "      <td>-0.247427</td>\n",
       "      <td>0.191884</td>\n",
       "      <td>0.082540</td>\n",
       "      <td>-0.176893</td>\n",
       "      <td>-0.292900</td>\n",
       "      <td>0.026866</td>\n",
       "      <td>-0.184774</td>\n",
       "      <td>-0.028962</td>\n",
       "      <td>0.136897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111189</td>\n",
       "      <td>-0.273562</td>\n",
       "      <td>-0.183656</td>\n",
       "      <td>0.097517</td>\n",
       "      <td>-0.479514</td>\n",
       "      <td>0.040613</td>\n",
       "      <td>-0.001686</td>\n",
       "      <td>0.375726</td>\n",
       "      <td>-0.039611</td>\n",
       "      <td>-0.224925</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035069</td>\n",
       "      <td>-0.387379</td>\n",
       "      <td>-0.100452</td>\n",
       "      <td>0.466866</td>\n",
       "      <td>-0.070174</td>\n",
       "      <td>-0.028153</td>\n",
       "      <td>-0.092408</td>\n",
       "      <td>-0.405352</td>\n",
       "      <td>0.017130</td>\n",
       "      <td>0.476657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.036425</td>\n",
       "      <td>0.037782</td>\n",
       "      <td>-0.021160</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.147599</td>\n",
       "      <td>0.058526</td>\n",
       "      <td>-0.114621</td>\n",
       "      <td>0.213723</td>\n",
       "      <td>0.059632</td>\n",
       "      <td>0.086401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150403</td>\n",
       "      <td>-0.541386</td>\n",
       "      <td>-0.157619</td>\n",
       "      <td>0.251735</td>\n",
       "      <td>0.137521</td>\n",
       "      <td>-0.044009</td>\n",
       "      <td>0.121063</td>\n",
       "      <td>-0.083002</td>\n",
       "      <td>-0.246977</td>\n",
       "      <td>0.457366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.080210</td>\n",
       "      <td>-0.115255</td>\n",
       "      <td>-0.419365</td>\n",
       "      <td>-0.184859</td>\n",
       "      <td>0.179399</td>\n",
       "      <td>0.127797</td>\n",
       "      <td>-0.352009</td>\n",
       "      <td>0.518455</td>\n",
       "      <td>0.039487</td>\n",
       "      <td>0.165133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005616</td>\n",
       "      <td>-0.135778</td>\n",
       "      <td>0.296242</td>\n",
       "      <td>0.392130</td>\n",
       "      <td>-0.203937</td>\n",
       "      <td>0.173051</td>\n",
       "      <td>0.126469</td>\n",
       "      <td>0.032222</td>\n",
       "      <td>0.041178</td>\n",
       "      <td>0.384974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.019885  0.252414 -0.152997  0.000558 -0.149843 -0.031965 -0.179896   \n",
       "1  0.243932 -0.007327 -0.160880  0.026103 -0.215708  0.092421 -0.032565   \n",
       "2  0.111189 -0.273562 -0.183656  0.097517 -0.479514  0.040613 -0.001686   \n",
       "3 -0.036425  0.037782 -0.021160  0.004696  0.147599  0.058526 -0.114621   \n",
       "4  0.080210 -0.115255 -0.419365 -0.184859  0.179399  0.127797 -0.352009   \n",
       "\n",
       "        7         8         9    ...       190       191       192       193  \\\n",
       "0  0.281747 -0.110417 -0.083372  ...  0.010679 -0.236222  0.138744  0.211952   \n",
       "1  0.176955  0.058125  0.112401  ...  0.073019 -0.247427  0.191884  0.082540   \n",
       "2  0.375726 -0.039611 -0.224925  ... -0.035069 -0.387379 -0.100452  0.466866   \n",
       "3  0.213723  0.059632  0.086401  ...  0.150403 -0.541386 -0.157619  0.251735   \n",
       "4  0.518455  0.039487  0.165133  ... -0.005616 -0.135778  0.296242  0.392130   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0 -0.148704 -0.124724 -0.137383 -0.320532  0.016711  0.225106  \n",
       "1 -0.176893 -0.292900  0.026866 -0.184774 -0.028962  0.136897  \n",
       "2 -0.070174 -0.028153 -0.092408 -0.405352  0.017130  0.476657  \n",
       "3  0.137521 -0.044009  0.121063 -0.083002 -0.246977  0.457366  \n",
       "4 -0.203937  0.173051  0.126469  0.032222  0.041178  0.384974  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T08:00:57.107537Z",
     "start_time": "2020-09-02T08:00:57.102390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49159, 200)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чат-бот\n",
    "\n",
    "Докрутить чат-бота (обучить лучший ft, w2v, взвесить idf). Модели сдампить и сложить в облако, ноутбук можно через гитхаб. \n",
    "\n",
    "> **тут пока не разобрался, буду разбираться ближе к курсовому**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
