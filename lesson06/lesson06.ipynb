{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ №6\n",
    "\n",
    "Провести сравнение RNN, LSTM, GRU на датасете отзывов (из предыдущих занятий/материалов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T23:28:28.997204Z",
     "start_time": "2020-09-18T23:28:28.873057Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D\n",
    "from keras.layers import SimpleRNN, LSTM, GRU, Masking\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T23:29:00.013964Z",
     "start_time": "2020-09-18T23:28:30.605200Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../lesson05/отзывы за лето.csv\", sep=';')\n",
    "data = data[data['Rating'] != 3]\n",
    "data['Content'] = data['Content'].apply(preprocess_text)\n",
    "data['Rating'] = data['Rating'] > 3\n",
    "data['Rating'] = data['Rating'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T23:29:00.045919Z",
     "start_time": "2020-09-18T23:29:00.018420Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data,  random_state=42, test_size=0.2)\n",
    "train, val  = train_test_split(train, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T23:29:00.056668Z",
     "start_time": "2020-09-18T23:29:00.049220Z"
    }
   },
   "outputs": [],
   "source": [
    "text_corpus_train = train['Content'].values\n",
    "text_corpus_valid = val['Content'].values\n",
    "text_corpus_test = test['Content'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T23:29:04.017813Z",
     "start_time": "2020-09-18T23:29:02.613106Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=None, \n",
    "                     filters='#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n',\n",
    "                     lower = False, split = ' ')\n",
    "tokenizer.fit_on_texts(text_corpus_train)\n",
    "\n",
    "sequences_train = tokenizer.texts_to_sequences(text_corpus_train)\n",
    "sequences_val = tokenizer.texts_to_sequences(text_corpus_valid)\n",
    "sequences_test = tokenizer.texts_to_sequences(text_corpus_test)\n",
    "\n",
    "word_count = len(tokenizer.index_word) + 1\n",
    "training_length = max([len(i.split()) for i in text_corpus_train])\n",
    "\n",
    "X_train = pad_sequences(sequences_train, maxlen=training_length)\n",
    "X_valid = pad_sequences(sequences_val, maxlen=training_length)\n",
    "X_test = pad_sequences(sequences_test, maxlen=training_length)\n",
    "\n",
    "y_train = train['Rating'].values\n",
    "y_val = val['Rating'].values\n",
    "y_test = test['Rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T23:29:05.131415Z",
     "start_time": "2020-09-18T23:29:05.123522Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    early_stopping=EarlyStopping(monitor='val_loss', patience=3)  \n",
    "\n",
    "    history = model.fit(X_train, y_train, batch_size=512, epochs=20, verbose=1,\n",
    "                        validation_data=(X_valid, y_val),\n",
    "                        callbacks=[early_stopping])\n",
    "\n",
    "    score = model.evaluate(X_test, y_test, batch_size=512, verbose=1)\n",
    "    print('\\n')\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T23:30:05.545386Z",
     "start_time": "2020-09-18T23:29:07.178458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12638 samples, validate on 3160 samples\n",
      "Epoch 1/20\n",
      "12638/12638 [==============================] - 9s 740us/step - loss: 0.4731 - accuracy: 0.8310 - val_loss: 0.3834 - val_accuracy: 0.8494\n",
      "Epoch 2/20\n",
      "12638/12638 [==============================] - 7s 522us/step - loss: 0.3347 - accuracy: 0.8677 - val_loss: 0.2806 - val_accuracy: 0.8858\n",
      "Epoch 3/20\n",
      "12638/12638 [==============================] - 7s 525us/step - loss: 0.2495 - accuracy: 0.9046 - val_loss: 0.2328 - val_accuracy: 0.9044\n",
      "Epoch 4/20\n",
      "12638/12638 [==============================] - 6s 513us/step - loss: 0.1838 - accuracy: 0.9316 - val_loss: 0.2110 - val_accuracy: 0.9120\n",
      "Epoch 5/20\n",
      "12638/12638 [==============================] - 7s 516us/step - loss: 0.1297 - accuracy: 0.9547 - val_loss: 0.2046 - val_accuracy: 0.9222\n",
      "Epoch 6/20\n",
      "12638/12638 [==============================] - 6s 514us/step - loss: 0.0932 - accuracy: 0.9675 - val_loss: 0.2249 - val_accuracy: 0.9149\n",
      "Epoch 7/20\n",
      "12638/12638 [==============================] - 7s 540us/step - loss: 0.2672 - accuracy: 0.9142 - val_loss: 2.6224 - val_accuracy: 0.1877\n",
      "Epoch 8/20\n",
      "12638/12638 [==============================] - 7s 571us/step - loss: 0.6570 - accuracy: 0.7968 - val_loss: 0.3070 - val_accuracy: 0.8703\n",
      "3950/3950 [==============================] - 1s 182us/step\n",
      "\n",
      "\n",
      "Test score: 0.30267509378964386\n",
      "Test accuracy: 0.8691139221191406\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(SimpleRNN(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T23:32:36.286533Z",
     "start_time": "2020-09-18T23:30:05.549898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12638 samples, validate on 3160 samples\n",
      "Epoch 1/20\n",
      "12638/12638 [==============================] - 21s 2ms/step - loss: 0.5248 - accuracy: 0.8324 - val_loss: 0.3892 - val_accuracy: 0.8494\n",
      "Epoch 2/20\n",
      "12638/12638 [==============================] - 18s 1ms/step - loss: 0.3479 - accuracy: 0.8508 - val_loss: 0.2865 - val_accuracy: 0.8741\n",
      "Epoch 3/20\n",
      "12638/12638 [==============================] - 19s 1ms/step - loss: 0.2589 - accuracy: 0.8978 - val_loss: 0.2372 - val_accuracy: 0.8997\n",
      "Epoch 4/20\n",
      "12638/12638 [==============================] - 18s 1ms/step - loss: 0.2052 - accuracy: 0.9212 - val_loss: 0.2084 - val_accuracy: 0.9076\n",
      "Epoch 5/20\n",
      "12638/12638 [==============================] - 18s 1ms/step - loss: 0.1632 - accuracy: 0.9374 - val_loss: 0.2012 - val_accuracy: 0.9146\n",
      "Epoch 6/20\n",
      "12638/12638 [==============================] - 18s 1ms/step - loss: 0.1312 - accuracy: 0.9520 - val_loss: 0.2061 - val_accuracy: 0.9190\n",
      "Epoch 7/20\n",
      "12638/12638 [==============================] - 18s 1ms/step - loss: 0.1072 - accuracy: 0.9623 - val_loss: 0.2110 - val_accuracy: 0.9149\n",
      "Epoch 8/20\n",
      "12638/12638 [==============================] - 18s 1ms/step - loss: 0.0866 - accuracy: 0.9698 - val_loss: 0.2237 - val_accuracy: 0.9187\n",
      "3950/3950 [==============================] - 2s 389us/step\n",
      "\n",
      "\n",
      "Test score: 0.22513175246081774\n",
      "Test accuracy: 0.9154430627822876\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(LSTM(64, recurrent_dropout=0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T23:34:44.865296Z",
     "start_time": "2020-09-18T23:32:36.290902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12638 samples, validate on 3160 samples\n",
      "Epoch 1/20\n",
      "12638/12638 [==============================] - 17s 1ms/step - loss: 0.5493 - accuracy: 0.8385 - val_loss: 0.4936 - val_accuracy: 0.8494\n",
      "Epoch 2/20\n",
      "12638/12638 [==============================] - 16s 1ms/step - loss: 0.3747 - accuracy: 0.8463 - val_loss: 0.3422 - val_accuracy: 0.8494\n",
      "Epoch 3/20\n",
      "12638/12638 [==============================] - 15s 1ms/step - loss: 0.2766 - accuracy: 0.8611 - val_loss: 0.2726 - val_accuracy: 0.8946\n",
      "Epoch 4/20\n",
      "12638/12638 [==============================] - 15s 1ms/step - loss: 0.2108 - accuracy: 0.9190 - val_loss: 0.2273 - val_accuracy: 0.9076\n",
      "Epoch 5/20\n",
      "12638/12638 [==============================] - 15s 1ms/step - loss: 0.1671 - accuracy: 0.9369 - val_loss: 0.2139 - val_accuracy: 0.9063\n",
      "Epoch 6/20\n",
      "12638/12638 [==============================] - 16s 1ms/step - loss: 0.1398 - accuracy: 0.9494 - val_loss: 0.2154 - val_accuracy: 0.9057\n",
      "Epoch 7/20\n",
      "12638/12638 [==============================] - 16s 1ms/step - loss: 0.1173 - accuracy: 0.9592 - val_loss: 0.2191 - val_accuracy: 0.9082\n",
      "Epoch 8/20\n",
      "12638/12638 [==============================] - 16s 1ms/step - loss: 0.0971 - accuracy: 0.9667 - val_loss: 0.2312 - val_accuracy: 0.9035\n",
      "3950/3950 [==============================] - 1s 317us/step\n",
      "\n",
      "\n",
      "Test score: 0.2352775572523286\n",
      "Test accuracy: 0.900253176689148\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(GRU(64, recurrent_dropout=0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "* можно сделать небольшой вывод о том что сети LSTM или GRU точно работают лучше чем Simple RNN\n",
    "* также возможно мне пказалось но с LSTM будет больше возможностей добиться большего качества "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
